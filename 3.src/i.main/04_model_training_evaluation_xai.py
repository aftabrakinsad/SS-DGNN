# -*- coding: utf-8 -*-
"""04_model_training_evaluation_xai.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16Fg89rdDEf4-f6dnzGpNQV0KcAx5Isn2
"""

!pip install -q torch torchvision torchaudio torch_geometric optuna scikit-learn

import os
import time
import torch
import random
import optuna
import numpy as np
import pandas as pd
import torch.nn as nn
import networkx as nx
import seaborn as sns
from pathlib import Path
import matplotlib.cm as cm
import torch.optim as optim
import matplotlib.pyplot as plt
import torch.nn.functional as F
from sklearn.manifold import TSNE
from torch_geometric.loader import DataLoader
from torch_geometric.nn import SAGEConv, GATConv, GCNConv
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    roc_auc_score, confusion_matrix, roc_curve, auc, matthews_corrcoef
)

SPLIT_GRAPHS_BASE_DIR = Path('/content/drive/MyDrive/ColabNotebooks/AnomalyDetection/graphs')
MODEL_SAVE_BASE_DIR = Path('/content/drive/MyDrive/ColabNotebooks/AnomalyDetection/ss_dgnn_model')
MODEL_SAVE_BASE_DIR.mkdir(parents=True, exist_ok=True)
MODEL_STATE_DICT_FILENAME = 'ss_dgnn_model.pt'
PROCESSED_CSV_PATH = Path('/content/drive/MyDrive/ColabNotebooks/AnomalyDetection/data/processedData/processed_NF-BoT-IoT-v2.2.csv')

numerical_features_used = [
    'L4_SRC_PORT', 'L4_DST_PORT', 'PROTOCOL', 'L7_PROTO', 'IN_BYTES', 'IN_PKTS',
    'OUT_BYTES', 'OUT_PKTS', 'TCP_FLAGS', 'CLIENT_TCP_FLAGS', 'SERVER_TCP_FLAGS',
    'FLOW_DURATION_MILLISECONDS', 'DURATION_IN', 'DURATION_OUT', 'MIN_TTL',
    'MAX_TTL', 'LONGEST_FLOW_PKT', 'SHORTEST_FLOW_PKT', 'MIN_IP_PKT_LEN',
    'MAX_IP_PKT_LEN', 'SRC_TO_DST_SECOND_BYTES', 'DST_TO_SRC_SECOND_BYTES',
    'RETRANSMITTED_IN_BYTES', 'RETRANSMITTED_IN_PKTS', 'RETRANSMITTED_OUT_BYTES',
    'RETRANSMITTED_OUT_PKTS', 'SRC_TO_DST_AVG_THROUGHPUT', 'DST_TO_SRC_AVG_THROUGHPUT',
    'NUM_PKTS_UP_TO_128_BYTES', 'NUM_PKTS_128_TO_256_BYTES', 'NUM_PKTS_256_TO_512_BYTES',
    'NUM_PKTS_512_TO_1024_BYTES', 'NUM_PKTS_1024_TO_1514_BYTES', 'TCP_WIN_MAX_IN',
    'TCP_WIN_MAX_OUT', 'ICMP_TYPE', 'ICMP_IPV4_TYPE', 'DNS_QUERY_ID',
    'DNS_QUERY_TYPE', 'DNS_TTL_ANSWER', 'FTP_COMMAND_RET_CODE'
]

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

class SS_DGNN(torch.nn.Module):
    def __init__(self, input_dim, hidden_dims, latent_dim, gnn_layer_type, activation_function):
        super(SS_DGNN, self).__init__()
        self.latent_dim = latent_dim
        self.num_layers = len(hidden_dims) + 1
        self.gnn_layer = self.get_gnn_layer(gnn_layer_type)
        self.activation = self.get_activation_function(activation_function)

        self.encoder_convs = nn.ModuleList()

        if self.num_layers == 1:
            self.encoder_convs.append(self.gnn_layer(input_dim, latent_dim))
        else:
            self.encoder_convs.append(self.gnn_layer(input_dim, hidden_dims[0]))

            for i in range(len(hidden_dims) - 1):
                self.encoder_convs.append(self.gnn_layer(hidden_dims[i], hidden_dims[i+1]))

            self.encoder_convs.append(self.gnn_layer(hidden_dims[-1], latent_dim))

        self.decoder_linear = nn.Linear(latent_dim, input_dim)

    def get_gnn_layer(self, layer_type):
        if layer_type == 'SAGEConv':
            return SAGEConv
        elif layer_type == 'GATConv':
            return GATConv
        elif layer_type == 'GCNConv':
            return GCNConv
        else:
            raise ValueError(f"Unknown GNN layer type: {layer_type}")

    def get_activation_function(self, activation_type):
        if activation_type == 'relu':
            return F.relu
        elif activation_type == 'leaky_relu':
            return F.leaky_relu
        elif activation_type == 'tanh':
            return torch.tanh
        elif activation_type == 'sigmoid':
            return torch.sigmoid
        else:
            raise ValueError(f"Unknown activation function: {activation_type}")

    def encode(self, x, edge_index):
        for i, conv_layer in enumerate(self.encoder_convs):
            x = conv_layer(x, edge_index)
            if i < self.num_layers - 1:
                x = self.activation(x)
        return x

    def decode(self, z):
        return self.decoder_linear(z)

    def forward(self, data):
        z = self.encode(data.x, data.edge_index)
        return self.decode(z)

def get_reconstruction_errors(graph_list, model, device):
    errors = []
    with torch.no_grad():
        for graph in graph_list:
            if graph.x.numel() == 0 or graph.edge_index.numel() == 0:
                errors.append(0.0)
                continue

            data = graph.to(device)
            reconstructed_x = model(data)
            error = F.mse_loss(reconstructed_x, data.x, reduction='mean').item()
            errors.append(error)
    return np.array(errors)

def get_detailed_reconstruction_errors(graph_list, model, device):
    overall_errors = []
    all_node_errors = []
    all_feature_errors = []
    all_node_feature_errors = []

    with torch.no_grad():
        for graph_idx, graph in enumerate(graph_list):
            if graph.x.numel() == 0 or graph.edge_index.numel() == 0:
                overall_errors.append(0.0)
                continue

            data = graph.to(device)
            reconstructed_x = model(data)

            element_wise_sq_error = F.mse_loss(reconstructed_x, data.x, reduction='none')

            graph_error = element_wise_sq_error.mean().item()
            overall_errors.append(graph_error)

            per_node_error = element_wise_sq_error.sum(dim=1).cpu()
            for node_local_idx, error_val in enumerate(per_node_error):
                all_node_errors.append({
                    'graph_idx': graph_idx,
                    'node_local_idx': node_local_idx,
                    'error': error_val.item()
                })

            per_feature_error = element_wise_sq_error.sum(dim=0).cpu()
            for feature_idx, error_val in enumerate(per_feature_error):
                all_feature_errors.append({
                    'graph_idx': graph_idx,
                    'feature_idx': feature_idx,
                    'error': error_val.item()
                })

            element_wise_sq_error_cpu = element_wise_sq_error.cpu()
            for node_local_idx in range(element_wise_sq_error_cpu.shape[0]):
                for feature_idx in range(element_wise_sq_error_cpu.shape[1]):
                    all_node_feature_errors.append({
                        'graph_idx': graph_idx,
                        'node_local_idx': node_local_idx,
                        'feature_idx': feature_idx,
                        'error': element_wise_sq_error_cpu[node_local_idx, feature_idx].item()
                    })

    return np.array(overall_errors), all_node_errors, all_feature_errors, all_node_feature_errors

def visualize_pyg_graph(pyg_graph, title, node_error_map=None, ip_node_labels=None, cmap_for_errors=cm.Reds):
    if pyg_graph is None or pyg_graph.num_nodes == 0 or pyg_graph.edge_index.numel() == 0:
        print(f"Cannot visualize '{title}': Graph is empty.")
        return

    G = nx.DiGraph()
    G.add_nodes_from(range(pyg_graph.num_nodes))
    edges_to_plot = pyg_graph.edge_index.t().tolist()
    G.add_edges_from(edges_to_plot)

    plt.figure(figsize=(10, 8))
    pos = nx.spring_layout(G, k=0.5, iterations=50, seed=42)

    cmap = cmap_for_errors
    node_colors = 'lightblue'

    if node_error_map:
        errors = np.array([node_error_map.get(i, 0) for i in range(pyg_graph.num_nodes)])
        if errors.max() > errors.min():
            norm_errors = (errors - errors.min()) / (errors.max() - errors.min())
        else:
            norm_errors = np.zeros_like(errors)
        node_colors = [cmap(error_val) for error_val in norm_errors]

    if ip_node_labels:
        node_labels_dict = {i: f"{ip_node_labels.get(i, f'Node {i}')}\n({i})" for i in range(pyg_graph.num_nodes)}
    else:
        node_labels_dict = {i: str(i) for i in range(pyg_graph.num_nodes)}

    nx.draw(G, pos,
            labels=node_labels_dict,
            with_labels=True,
            node_color=node_colors,
            node_size=700,
            edge_color='gray',
            width=1,
            arrowsize=10,
            font_size=8,
            font_color='black',
            alpha=0.9
           )

    plt.title(f"{title} (True Label: {pyg_graph.y.item()}) - {G.number_of_edges()} Edges Plotted")
    plt.axis('off')

    if node_error_map and errors.max() > errors.min():
        sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=errors.min(), vmax=errors.max()))
        sm.set_array([])
        cbar = plt.colorbar(sm, ax=plt.gca(), orientation='vertical', fraction=0.02, pad=0.04)
        cbar.set_label('Node Reconstruction Error')

    plt.show()

def generate_natural_language_explanation(graph_idx, node_errors, feature_errors, feature_names, threshold, overall_error, top_k=3, graph_type="graph"):
    if overall_error <= threshold:
        explanation = (
            f"This {graph_type} (Graph Index: {graph_idx}) is classified as BENIGN.\n"
            f"Its overall reconstruction error ({overall_error:.6f}) is below the anomaly threshold ({threshold:.6f}), "
            "indicating normal network behavior."
        )
        print(">>> Natural Language Explanation:")
        print(explanation)
        return explanation

    node_errors_filtered = [ne for ne in node_errors if not np.isnan(ne['error']) and ne['error'] > 1e-6]
    feature_errors_filtered = [fe for fe in feature_errors if not np.isnan(fe['error']) and fe['error'] > 1e-6]

    aggregated_node_errors = {ne['node_local_idx']: ne['error'] for ne in node_errors_filtered}
    sorted_nodes = sorted(aggregated_node_errors.items(), key=lambda item: item[1], reverse=True)[:top_k]
    node_str = ", ".join([f"node {idx} (Error: {err:.2f})" for idx, err in sorted_nodes]) if sorted_nodes else "no significant nodes"

    aggregated_feature_errors = {fe['feature_idx']: fe['error'] for fe in feature_errors_filtered}
    sorted_features = sorted(aggregated_feature_errors.items(), key=lambda item: item[1], reverse=True)[:top_k]
    feature_names_list = [feature_names[idx] for idx, err in sorted_features]
    feature_str = ", ".join([f"'{name}'" for name in feature_names_list]) if feature_names_list else "no significant features"

    explanation = (
        f"This {graph_type} (Graph Index: {graph_idx}) is **ANOMALOUS** "
        f"(Error: {overall_error:.6f} > Threshold: {threshold:.6f}).\n"
        f"The most suspicious nodes are {node_str}.\n"
        f"The features that contributed most significantly to this high anomaly score are {feature_str}, "
        "suggesting the anomaly involves **unusual values or patterns in these network metrics**."
    )
    print(">>> Natural Language Explanation:")
    print(explanation)
    return explanation

def plot_top_feature_errors(feature_errors, feature_names, top_n=10, bar_color='orange'):
    aggregated_feature_errors = {}
    for fe in feature_errors:
        if not np.isnan(fe['error']) and fe['error'] > 1e-6:
            feature_idx = fe['feature_idx']
            aggregated_feature_errors[feature_idx] = aggregated_feature_errors.get(feature_idx, 0) + fe['error']

    sorted_features = sorted(aggregated_feature_errors.items(), key=lambda item: item[1], reverse=True)[:top_n]

    if not sorted_features:
        return

    feature_labels = [feature_names[idx] for idx, err in sorted_features]
    errors = [err for idx, err in sorted_features]

    plt.figure(figsize=(10, 5))
    plt.barh(feature_labels[::-1], errors[::-1], color=bar_color)
    plt.xlabel("Total Reconstruction Error", fontweight='bold')
    #plt.title(f"Top {len(sorted_features)} Feature Reconstruction Errors")
    plt.tight_layout()
    plt.show()

def plot_top_node_errors(node_errors, ip_node_labels, top_n=5, bar_color='orange'):
    aggregated_node_errors = {}
    for ne in node_errors:
        if not np.isnan(ne['error']) and ne['error'] > 1e-6:
            node_local_idx = ne['node_local_idx']
            aggregated_node_errors[node_local_idx] = aggregated_node_errors.get(node_local_idx, 0) + ne['error']

    sorted_nodes = sorted(aggregated_node_errors.items(), key=lambda item: item[1], reverse=True)[:top_n]

    if not sorted_nodes:
        return

    node_labels = []
    errors = []
    for node_local_idx, error_val in sorted_nodes:
        ip_addr = ip_node_labels.get(node_local_idx, f'Node {node_local_idx}')
        node_labels.append(f"{ip_addr}\n(ID: {node_local_idx})")
        errors.append(error_val)

    plt.figure(figsize=(10, 5))
    plt.barh(node_labels[::-1], errors[::-1], color=bar_color)
    plt.xlabel("Total Reconstruction Error", fontweight='bold')
    #plt.title(f"Top {len(sorted_nodes)} Node Reconstruction Errors")
    plt.tight_layout()
    plt.show()

def get_graph_embeddings(graph_list, model, device):
    embeddings = []
    labels = []
    with torch.no_grad():
        for graph in graph_list:
            if graph.x.numel() == 0 or graph.edge_index.numel() == 0:
                embeddings.append(torch.zeros(model.latent_dim).cpu().numpy())
                labels.append(graph.y.item())
                continue

            data = graph.to(device)
            node_embeddings = model.encode(data.x, data.edge_index)
            graph_embedding = node_embeddings.mean(dim=0)
            embeddings.append(graph_embedding.cpu().numpy())
            labels.append(graph.y.item())
    return np.array(embeddings), np.array(labels)

try:
    train_benign_graphs_cpu = torch.load(SPLIT_GRAPHS_BASE_DIR / 'train_graphs_benign.pt', weights_only=False)
    val_benign_graphs_cpu = torch.load(SPLIT_GRAPHS_BASE_DIR / 'val_graphs_benign.pt', weights_only=False)
    test_graphs_cpu = torch.load(SPLIT_GRAPHS_BASE_DIR / 'test_graphs_mixed.pt', weights_only=False)

    metadata = torch.load(SPLIT_GRAPHS_BASE_DIR / 'graph_metadata.pt', weights_only=False)
    WINDOW_SIZE = metadata.get('window_size', 500)

    print(f"Loaded {len(train_benign_graphs_cpu)} benign training, {len(val_benign_graphs_cpu)} benign validation, and {len(test_graphs_cpu)} mixed test graphs (on CPU).")
    print(f"Using WINDOW_SIZE: {WINDOW_SIZE}")

    train_benign_graphs = [g.to(device) for g in train_benign_graphs_cpu]
    val_benign_graphs = [g.to(device) for g in val_benign_graphs_cpu]
    test_graphs = [g.to(device) for g in test_graphs_cpu]

    print(f"Moved graphs to {device}.")

    original_df = pd.read_csv(PROCESSED_CSV_PATH)
    print(f"Loaded original DataFrame from {PROCESSED_CSV_PATH} for XAI mapping.")

except FileNotFoundError as e:
    raise FileNotFoundError(f"Error: Required graph or data files not found. "
                             f"Make sure paths are correct: {SPLIT_GRAPHS_BASE_DIR} and {PROCESSED_CSV_PATH}. Error: {e}")
except Exception as e:
    raise RuntimeError(f"An unexpected error occurred while loading split graphs or original data: {e}")

if not train_benign_graphs:
    raise ValueError("No benign training graphs found. Cannot proceed.")
if not val_benign_graphs:
    raise ValueError("No benign validation graphs found. Cannot proceed.")
if not test_graphs:
    raise ValueError("No test graphs found. Cannot proceed.")

try:
    input_dim = train_benign_graphs[0].x.shape[1]
except IndexError:
    raise ValueError("Training graph list is empty or graph has no features.")

original_feature_len = len(numerical_features_used)

if input_dim != original_feature_len:
    print(f"Model input dim ({input_dim}) != Original features ({original_feature_len}).")
    print("Generating statistical feature names (Mean, Max, Std)...")

    stats = ['Mean', 'Max', 'Std']

    new_xai_feature_names = []
    for stat in stats:
        for feature in numerical_features_used:
             new_xai_feature_names.append(f"{stat}_{feature}")

    numerical_features_used = new_xai_feature_names

    print(f"Generated {len(numerical_features_used)} feature names.")
    print(f"Example: Index 80 is now '{numerical_features_used[80]}'")
    print(f"Example: Index 40 is now '{numerical_features_used[40]}'")

def objective(trial: optuna.Trial):
    gnn_layer_type = trial.suggest_categorical('gnn_layer_type', ['SAGEConv', 'GATConv', 'GCNConv'])
    activation_function = trial.suggest_categorical('activation_function', ['relu', 'leaky_relu', 'tanh', 'sigmoid'])

    num_layers = trial.suggest_int('num_layers', 1, 7)
    hidden_dims = []
    if num_layers > 1:
        for i in range(num_layers - 1):
            hidden_dims.append(trial.suggest_categorical(f'hidden_dim_layer_{i}', [32, 64, 128]))
    latent_dim = trial.suggest_int('latent_dim', 32, 128, step=32)

    model = SS_DGNN(input_dim, hidden_dims, latent_dim, gnn_layer_type, activation_function).to(device)

    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64])
    lr = trial.suggest_float('lr', 1e-4, 5e-3, log=True)
    optimizer_name = trial.suggest_categorical('optimizer_name', ['RMSprop', 'Adam', 'SDG'])

    if optimizer_name == 'Adam':
        optimizer = optim.Adam(model.parameters(), lr=lr)
    else:
        optimizer = optim.RMSprop(model.parameters(), lr=lr)

    criterion = nn.MSELoss()
    num_epochs = trial.suggest_int('num_epochs_max', 50, 150, step=50)
    patience = trial.suggest_int('patience', 10, 30)

    train_loader = DataLoader(train_benign_graphs, batch_size=batch_size, shuffle=True)

    best_val_loss = float('inf')
    counter = 0

    for epoch in range(1, num_epochs + 1):
        model.train()
        total_train_loss = 0

        for data in train_loader:
            if data.x.numel() == 0 or data.edge_index.numel() == 0: continue
            data = data.to(device)
            optimizer.zero_grad()
            reconstructed_x = model(data)
            loss = criterion(reconstructed_x, data.x)
            loss.backward()
            optimizer.step()
            total_train_loss += loss.item() * data.num_graphs

        avg_train_loss = total_train_loss / len(train_loader.dataset) if len(train_loader.dataset) > 0 else 0

        model.eval()
        val_reconstruction_errors = get_reconstruction_errors(val_benign_graphs, model, device)
        avg_val_loss_for_es = val_reconstruction_errors.mean() if len(val_reconstruction_errors) > 0 else float('inf')

        trial.report(avg_val_loss_for_es, epoch)

        if avg_val_loss_for_es < best_val_loss:
            best_val_loss = avg_val_loss_for_es
            counter = 0
        else:
            counter += 1
            if counter >= patience:
                break

        if trial.should_prune():
            raise optuna.exceptions.TrialPruned()

    return best_val_loss

print("Starting Optuna optimization for SS_DGNN hyperparameters...")
sampler = optuna.samplers.TPESampler(seed=42)
study = optuna.create_study(direction="minimize", sampler=sampler)
study.optimize(objective, n_trials=100, show_progress_bar=True)

print("--- Optuna Optimization Results ---")
print(f"Best trial number: {study.best_trial.number}")
print(f"Best validation reconstruction loss: {study.best_value:.4f}")
print("Best hyperparameters:")
for key, value in study.best_params.items():
    print(f"  {key}: {value}")

print("--- Training Final Model with Best Hyperparameters ---")
best_params = study.best_params

num_layers = best_params['num_layers']
best_hidden_dims = []
if num_layers > 1:
    for i in range(num_layers - 1):
        best_hidden_dims.append(best_params[f'hidden_dim_layer_{i}'])
best_latent_dim = best_params['latent_dim']
best_gnn_layer_type = best_params['gnn_layer_type']
best_activation_function = best_params['activation_function']
best_optimizer_name = best_params['optimizer_name']
best_lr = best_params['lr']
best_batch_size = best_params['batch_size']
best_num_epochs = best_params['num_epochs_max']
best_patience = best_params['patience']

final_model = SS_DGNN(input_dim, best_hidden_dims, best_latent_dim, best_gnn_layer_type, best_activation_function).to(device)
print(f"Final Model: {final_model.gnn_layer.__name__} based SS_DGNN, Hidden: {best_hidden_dims}, Latent: {best_latent_dim}")

if best_optimizer_name == 'Adam':
    final_optimizer = optim.Adam(final_model.parameters(), lr=best_lr)
else:
    final_optimizer = optim.RMSprop(final_model.parameters(), lr=best_lr)

final_criterion = nn.MSELoss()

combined_benign_graphs = train_benign_graphs + val_benign_graphs
final_train_loader = DataLoader(combined_benign_graphs, batch_size=best_batch_size, shuffle=True)

best_final_val_loss = float('inf')
final_counter = 0

training_start_time = time.time()

train_losses_history = []
val_losses_history = []
train_acc_history = []
val_acc_history = []

for epoch in range(1, best_num_epochs + 1):
    final_model.train()
    total_train_loss = 0
    total_train_correct = 0
    total_train_elements = 0

    for data in final_train_loader:
        if data.x.numel() == 0 or data.edge_index.numel() == 0:
            continue
        data = data.to(device)
        final_optimizer.zero_grad()
        reconstructed_x = final_model(data)

        loss = final_criterion(reconstructed_x, data.x)

        loss.backward()
        final_optimizer.step()
        total_train_loss += loss.item() * data.num_graphs

        correct = (torch.abs(reconstructed_x - data.x) < 0.1).sum().item()
        total = data.x.numel()
        total_train_correct += correct
        total_train_elements += total

    avg_train_loss = total_train_loss / len(final_train_loader.dataset) if len(final_train_loader.dataset) > 0 else 0
    avg_train_acc = total_train_correct / total_train_elements if total_train_elements > 0 else 0
    train_losses_history.append(avg_train_loss)
    train_acc_history.append(avg_train_acc)

    final_model.eval()
    final_val_benign_errors = get_reconstruction_errors(val_benign_graphs, final_model, device)
    avg_val_loss_for_es = final_val_benign_errors.mean() if len(final_val_benign_errors) > 0 else float('inf')
    val_losses_history.append(avg_val_loss_for_es)

    val_correct = 0
    val_total = 0
    for data in val_benign_graphs:
        data = data.to(device)
        reconstructed_x = final_model(data)
        val_correct += (torch.abs(reconstructed_x - data.x) < 0.1).sum().item()
        val_total += data.x.numel()
    avg_val_acc = val_correct / val_total if val_total > 0 else 0
    val_acc_history.append(avg_val_acc)


    if epoch % 10 == 0 or epoch == 1:
        print(f"Final Train Epoch {epoch:03d}, "
              f"Train Loss: {avg_train_loss:.4f}, Train Acc: {avg_train_acc:.4f}, "
              f"Val Loss (Benign): {avg_val_loss_for_es:.4f}, Val Acc: {avg_val_acc:.4f}")

    if avg_val_loss_for_es < best_final_val_loss:
        best_final_val_loss = avg_val_loss_for_es
        torch.save(final_model.state_dict(), MODEL_SAVE_BASE_DIR / MODEL_STATE_DICT_FILENAME)
        final_counter = 0
    else:
        final_counter += 1
        if final_counter >= best_patience:
            print(f"Early stopping final training at epoch {epoch}")
            break

print(f"Final trained SS_DGNN model saved to: {MODEL_SAVE_BASE_DIR / MODEL_STATE_DICT_FILENAME}")
print(f"Total Final Training Time: {time.time() - training_start_time:.2f} seconds")

plt.figure(figsize=(15, 6))

plt.subplot(1, 2, 1)
plt.plot(train_losses_history, label='Training Loss', color='blue')
plt.plot(val_losses_history, label='Validation Loss', color='orange')
plt.xlabel('Epoch', fontweight='bold')
plt.ylabel('Reconstruction Loss (MSE)', fontweight='bold')
#plt.title('Training and Validation Reconstruction Loss')
plt.legend()
plt.grid(False)

plt.subplot(1, 2, 2)
plt.plot(train_acc_history, label='Training Accuracy', color='green')
plt.plot(val_acc_history, label='Validation Accuracy', color='red')
plt.xlabel('Epoch', fontweight='bold')
plt.ylabel('Reconstruction Accuracy', fontweight='bold')
#lt.title('Training and Validation Reconstruction Accuracy)')
plt.legend()
plt.grid(False)

plt.show()

try:
    model_path = MODEL_SAVE_BASE_DIR / MODEL_STATE_DICT_FILENAME
    final_model.load_state_dict(torch.load(model_path, map_location=device))
    final_model.eval()
    print(f"Loaded best trained model state_dict for final evaluation from: {model_path}")
except Exception as e:
    raise RuntimeError(f"An unexpected error occurred while loading the final model state_dict for evaluation: {e}")

final_threshold_percentile = 95.0
print(f"Using threshold percentile: {final_threshold_percentile:.2f}%")

print("Calculating reconstruction errors for validation benign graphs (for final thresholding)...")
if val_benign_graphs:
    val_benign_reconstruction_errors = get_reconstruction_errors(val_benign_graphs, final_model, device)
else:
    raise ValueError("No benign validation graphs found to calculate threshold. Cannot proceed with evaluation.")

final_threshold = np.percentile(val_benign_reconstruction_errors, final_threshold_percentile)
print(f"Final Threshold: {final_threshold:.6f}")

print("Calculating reconstruction errors for test graphs (inference)...")
inference_start_time = time.time()
test_reconstruction_errors = get_reconstruction_errors(test_graphs, final_model, device)
inference_end_time = time.time()
inference_duration = inference_end_time - inference_start_time

valid_test_indices = np.where(~np.isnan(test_reconstruction_errors) & (test_reconstruction_errors > 1e-6))[0]
test_reconstruction_errors_filtered = test_reconstruction_errors[valid_test_indices]
test_true_labels_filtered = np.array([g.y.item() for g in test_graphs])[valid_test_indices]

predicted_labels = (test_reconstruction_errors_filtered > final_threshold).astype(int)

accuracy = accuracy_score(test_true_labels_filtered, predicted_labels)
precision = precision_score(test_true_labels_filtered, predicted_labels)
recall = recall_score(test_true_labels_filtered, predicted_labels)
f1 = f1_score(test_true_labels_filtered, predicted_labels)
mcc = matthews_corrcoef(test_true_labels_filtered, predicted_labels)
roc_auc = roc_auc_score(test_true_labels_filtered, test_reconstruction_errors_filtered)

print(f"--- Final Evaluation Metrics on Test Set (Threshold: {final_threshold:.6f}) ---")
print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1-Score: {f1:.4f}")
print(f"MCC: {mcc:.4f}")
print(f"ROC AUC: {roc_auc:.4f}")
print(f"Model Inference Time (Test Set): {inference_duration:.4f} seconds")

conf_matrix = confusion_matrix(test_true_labels_filtered, predicted_labels)
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,
            xticklabels=['Predicted Benign (0)', 'Predicted Attack (1)'],
            yticklabels=['Actual Benign (0)', 'Actual Attack (1)'])
#plt.title('Confusion Matrix (Zero-Day Detection)', fontweight='bold')
plt.xlabel('Predicted Label', fontweight='bold')
plt.ylabel('True Label', fontweight='bold')
plt.show()

plt.figure(figsize=(8, 6))
fpr, tpr, _ = roc_curve(test_true_labels_filtered, test_reconstruction_errors_filtered)
roc_auc_val = auc(fpr, tpr)
plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc_val:.2f})', color='darkorange')
plt.plot([0, 1], [0, 1], linestyle='--', color='navy')
plt.xlabel('False Positive Rate', fontweight='bold')
plt.ylabel('True Positive Rate', fontweight='bold')
#plt.title('Receiver Operating Characteristic (ROC) Curve (Test Set)', fontweight='bold')
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(10, 6))
sns.histplot(test_reconstruction_errors_filtered[test_true_labels_filtered == 0], bins=50, kde=True, color='green', label='Benign Errors')
sns.histplot(test_reconstruction_errors_filtered[test_true_labels_filtered == 1], bins=50, kde=True, color='red', label='Attack Errors')
plt.axvline(final_threshold, color='blue', linestyle='--', label=f'Threshold: {final_threshold:.6f}')
plt.xlabel('Reconstruction Error', fontweight='bold')
plt.ylabel('Density / Count', fontweight='bold')
#plt.title('Reconstruction Error Distribution for Test Graphs', fontweight='bold')
plt.legend()
plt.grid(True)
plt.show()

embeddings, labels = get_graph_embeddings(test_graphs, final_model, device)

tsne_perplexity = min(30, len(embeddings)-1) if len(embeddings) > 1 else 1
tsne_max_iter = 1000
tsne_learning_rate = 200

if embeddings.shape[0] > 1 and embeddings.shape[1] > 0:
    tsne = TSNE(n_components=2, random_state=42, perplexity=tsne_perplexity, max_iter=tsne_max_iter, learning_rate=tsne_learning_rate)
    embeddings_2d = tsne.fit_transform(embeddings)

    plt.figure(figsize=(8, 6))
    plt.scatter(embeddings_2d[labels == 0][:, 0], embeddings_2d[labels == 0][:, 1], c='green', label='Benign', alpha=0.6, s=20, marker='o')
    plt.scatter(embeddings_2d[labels == 1][:, 0], embeddings_2d[labels == 1][:, 1], c='red', label='Attack', alpha=0.7, s=20, marker='x')
    plt.xlabel('t-SNE Component 1', fontweight='bold')
    plt.ylabel('t-SNE Component 2', fontweight='bold')
    #plt.title('t-SNE Visualization of Graph Embeddings (Test Set)', fontweight='bold')
    plt.legend()
    plt.grid(True, linestyle='--', alpha=0.6)
    plt.show()
else:
    print("Not enough valid graph embeddings to perform t-SNE visualization.")

NUM_EXPLANATIONS = 3

print("--- Explainable AI (XAI) for Top Anomalies ---")
print("Calculating detailed reconstruction errors for test graphs for XAI...")

test_graphs_for_xai = [test_graphs[i] for i in valid_test_indices]
test_graph_errors_for_xai, test_node_errors, test_feature_errors, test_node_feature_errors = \
    get_detailed_reconstruction_errors(test_graphs_for_xai, final_model, device)

sorted_anomaly_indices = np.argsort(test_reconstruction_errors_filtered)[::-1]
top_anomaly_original_indices = [valid_test_indices[i] for i in sorted_anomaly_indices]

print(f"Using final threshold: {final_threshold:.6f}")
print(f"Found {len(predicted_labels[predicted_labels == 1])} predicted anomalies in test set.")

for i, original_graph_idx in enumerate(top_anomaly_original_indices[:NUM_EXPLANATIONS]):

    anomaly_graph = test_graphs[original_graph_idx]

    filtered_list_idx = np.where(valid_test_indices == original_graph_idx)[0][0]

    overall_error = test_graph_errors_for_xai[filtered_list_idx]

    print(f"=== Detected Anomaly #{i+1} (Original Test Graph Index: {original_graph_idx}) ===")
    print(f"True label: {anomaly_graph.y.item()}")
    print(f"Overall reconstruction error: {overall_error:.6f}")

    start_row_idx_for_test_graph = original_graph_idx * WINDOW_SIZE
    end_row_idx_for_test_graph = min(start_row_idx_for_test_graph + WINDOW_SIZE, len(original_df))
    current_window_df = original_df.iloc[start_row_idx_for_test_graph : end_row_idx_for_test_graph]

    current_ips = pd.concat([current_window_df['IPV4_SRC_ADDR'], current_window_df['IPV4_DST_ADDR']]).unique()
    local_idx_to_ip = {idx: ip for idx, ip in enumerate(current_ips)}

    graph_specific_node_errors = [ne for ne in test_node_errors if ne['graph_idx'] == filtered_list_idx]
    graph_specific_feature_errors = [fe for fe in test_feature_errors if fe['graph_idx'] == filtered_list_idx]

    top_nodes = sorted([ne for ne in graph_specific_node_errors if not np.isnan(ne['error']) and ne['error'] > 1e-6],
                       key=lambda x: x['error'], reverse=True)[:5]
    print("\nTop 5 nodes by reconstruction error (The 'Who' of the anomaly):")
    if top_nodes:
        for node_info in top_nodes:
            ip_addr = local_idx_to_ip.get(node_info['node_local_idx'], 'UNKNOWN_IP')
            print(f"  Node {node_info['node_local_idx']} (IP: {ip_addr}) - Error: {node_info['error']:.6f}")
    else:
        print("  No significant node errors for this graph.")

    top_features = sorted([fe for fe in graph_specific_feature_errors if not np.isnan(fe['error']) and fe['error'] > 1e-6],
                          key=lambda x: x['error'], reverse=True)[:5]
    print("\nTop 5 features by reconstruction error (The 'What' of the anomaly):")
    if top_features:
        for feature_info in top_features:
            feature_name = numerical_features_used[feature_info['feature_idx']]
            print(f"  Feature '{feature_name}' - Error: {feature_info['error']:.6f}")
    else:
        print("  No significant feature errors for this graph.")

    generate_natural_language_explanation(
        original_graph_idx,
        graph_specific_node_errors,
        graph_specific_feature_errors,
        numerical_features_used,
        threshold=final_threshold,
        overall_error=overall_error,
        graph_type="anomalous graph"
    )

    plot_top_node_errors(graph_specific_node_errors, local_idx_to_ip, bar_color='red')
    plot_top_feature_errors(graph_specific_feature_errors, numerical_features_used, bar_color='red')

    node_error_map = {ne['node_local_idx']: ne['error'] for ne in graph_specific_node_errors}
    visualize_pyg_graph(anomaly_graph,
                        f"Detected Anomaly #{i+1} (Test Graph Index: {original_graph_idx})",
                        node_error_map=node_error_map,
                        ip_node_labels=local_idx_to_ip,
                        cmap_for_errors=cm.Reds)

print("--- Explainable AI (XAI) for Normal Samples ---")
num_benign_to_visualize = min(NUM_EXPLANATIONS, len(val_benign_graphs))
if num_benign_to_visualize == 0:
    print("No benign validation graphs available to visualize.")
else:
    val_benign_overall_errors_detailed, val_benign_node_errors, val_benign_feature_errors, _ = \
        get_detailed_reconstruction_errors(val_benign_graphs, final_model, device)

    benign_graph_indices_to_plot = random.sample(range(len(val_benign_graphs)), num_benign_to_visualize)
    benign_graph_indices_to_plot.sort()

    for i, val_list_idx in enumerate(benign_graph_indices_to_plot):
        benign_graph = val_benign_graphs[val_list_idx]
        overall_error = val_benign_overall_errors_detailed[val_list_idx]

        print(f"\n=== Normal Sample #{i+1} (Validation List Index: {val_list_idx}) ===")
        print(f"True label: {benign_graph.y.item()}")
        print(f"Overall reconstruction error: {overall_error:.6f} (Below threshold: {final_threshold:.6f})")

        graph_specific_node_errors = [ne for ne in val_benign_node_errors if ne['graph_idx'] == val_list_idx]
        graph_specific_feature_errors = [fe for fe in val_benign_feature_errors if fe['graph_idx'] == val_list_idx]

        local_idx_to_ip = {i: f"Node {i}" for i in range(benign_graph.num_nodes)}

        top_nodes = sorted([ne for ne in graph_specific_node_errors if not np.isnan(ne['error']) and ne['error'] > 1e-6],
                           key=lambda x: x['error'], reverse=True)[:5]
        print("\nTop 5 nodes by reconstruction error (The 'Who' of the normal sample):")
        if top_nodes:
            for node_info in top_nodes:
                ip_addr = local_idx_to_ip.get(node_info['node_local_idx'], 'UNKNOWN_IP')
                print(f"  Node {node_info['node_local_idx']} (IP: {ip_addr}) - Error: {node_info['error']:.6f}")
        else:
            print("  No significant node errors for this graph.")

        top_features = sorted([fe for fe in graph_specific_feature_errors if not np.isnan(fe['error']) and fe['error'] > 1e-6],
                              key=lambda x: x['error'], reverse=True)[:5]
        print("\nTop 5 features by reconstruction error (The 'What' of the normal sample):")
        if top_features:
            for feature_info in top_features:
                feature_name = numerical_features_used[feature_info['feature_idx']]
                print(f"  Feature '{feature_name}' - Error: {feature_info['error']:.6f}")
        else:
            print("  No significant feature errors for this graph.")

        plot_top_node_errors(graph_specific_node_errors, local_idx_to_ip, bar_color='green')
        plot_top_feature_errors(graph_specific_feature_errors, numerical_features_used, bar_color='green')

        generate_natural_language_explanation(
            val_list_idx,
            graph_specific_node_errors,
            graph_specific_feature_errors,
            numerical_features_used,
            threshold=final_threshold,
            overall_error=overall_error,
            graph_type="normal graph"
        )

        node_error_map = {ne['node_local_idx']: ne['error'] for ne in graph_specific_node_errors}
        visualize_pyg_graph(benign_graph,
                            f"Normal Sample #{i+1} (Validation Index: {val_list_idx})",
                            node_error_map=node_error_map,
                            ip_node_labels=local_idx_to_ip,
                            cmap_for_errors=cm.Greens)