# -*- coding: utf-8 -*-
"""02_graph_construction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KOWkO9EdJomdSYB3SV9asGZDl6KtSh7B
"""

!pip install -q torch torch_geometric

import os
import torch
import random
import zipfile
import numpy as np
import pandas as pd
from tqdm import tqdm
import networkx as nx
from pathlib import Path
import matplotlib.pyplot as plt
from torch_geometric.data import Data
from torch_geometric.utils import to_undirected

data_csv_path = Path('/content/drive/MyDrive/ColabNotebooks/AnomalyDetection/data/processedData/processed_NF-BoT-IoT-v2.2.csv')

df = pd.read_csv(data_csv_path)

WINDOW_SIZE = 500
print(f"Window size: {WINDOW_SIZE}")

label_column = 'Attack_Type'

numerical_features = [
    'L4_SRC_PORT', 'L4_DST_PORT', 'PROTOCOL', 'L7_PROTO', 'IN_BYTES', 'IN_PKTS',
    'OUT_BYTES', 'OUT_PKTS', 'TCP_FLAGS', 'CLIENT_TCP_FLAGS', 'SERVER_TCP_FLAGS',
    'FLOW_DURATION_MILLISECONDS', 'DURATION_IN', 'DURATION_OUT', 'MIN_TTL',
    'MAX_TTL', 'LONGEST_FLOW_PKT', 'SHORTEST_FLOW_PKT', 'MIN_IP_PKT_LEN',
    'MAX_IP_PKT_LEN', 'SRC_TO_DST_SECOND_BYTES', 'DST_TO_SRC_SECOND_BYTES',
    'RETRANSMITTED_IN_BYTES', 'RETRANSMITTED_IN_PKTS', 'RETRANSMITTED_OUT_BYTES',
    'RETRANSMITTED_OUT_PKTS', 'SRC_TO_DST_AVG_THROUGHPUT', 'DST_TO_SRC_AVG_THROUGHPUT',
    'NUM_PKTS_UP_TO_128_BYTES', 'NUM_PKTS_128_TO_256_BYTES', 'NUM_PKTS_256_TO_512_BYTES',
    'NUM_PKTS_512_TO_1024_BYTES', 'NUM_PKTS_1024_TO_1514_BYTES', 'TCP_WIN_MAX_IN',
    'TCP_WIN_MAX_OUT', 'ICMP_TYPE', 'ICMP_IPV4_TYPE', 'DNS_QUERY_ID',
    'DNS_QUERY_TYPE', 'DNS_TTL_ANSWER', 'FTP_COMMAND_RET_CODE'
]
numerical_features = [col for col in numerical_features if col in df.columns]
print(f"Using {len(numerical_features)} numerical features.")

def build_graphs(df, window_size, features, label_col, make_undirected=True):
    graphs = []

    df[features] = df[features].astype('float32')

    for i in tqdm(range(0, len(df), window_size), desc="Constructing Graphs"):
        window_df = df.iloc[i : i + window_size]
        if window_df.empty:
            continue

        current_ips = pd.concat([window_df['IPV4_SRC_ADDR'], window_df['IPV4_DST_ADDR']]).unique()
        local_ip_to_idx = {ip: idx for idx, ip in enumerate(current_ips)}

        node_features = []
        for ip in current_ips:
            flows = window_df[(window_df['IPV4_SRC_ADDR'] == ip) | (window_df['IPV4_DST_ADDR'] == ip)]
            if not flows.empty:
                aggregated_features = flows[features].agg(['mean', 'max', 'std'], axis=0).fillna(0).values.flatten()
                node_features.append(aggregated_features)
            else:
                node_features.append(np.zeros(len(features) * 3, dtype=np.float32))

        x = torch.tensor(np.array(node_features), dtype=torch.float)

        try:
            src_nodes = [local_ip_to_idx[ip] for ip in window_df['IPV4_SRC_ADDR']]
            dst_nodes = [local_ip_to_idx[ip] for ip in window_df['IPV4_DST_ADDR']]
        except KeyError as e:
            continue

        edge_index = torch.tensor([src_nodes, dst_nodes], dtype=torch.long)

        edge_attr_original = torch.tensor(window_df[features].values, dtype=torch.float)

        if make_undirected:
            edge_index, edge_attr = to_undirected(edge_index, edge_attr_original, num_nodes=len(current_ips))
        else:
            edge_attr = edge_attr_original

        y = torch.tensor([1 if (window_df[label_col] != 0).any() else 0], dtype=torch.long)

        if edge_index.shape[1] == 0:
            continue

        graph = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y, num_nodes=len(current_ips))
        graphs.append(graph)

    return graphs

graph_sequence = build_graphs(df, WINDOW_SIZE, numerical_features, label_col=label_column, make_undirected=True)

new_feat_dim = graph_sequence[0].x.shape[1] if graph_sequence else 0
print(f"Final Node Feature Dimension: {new_feat_dim}")
print(f"Generated {len(graph_sequence)} graph objects.")

save_dir = Path('/content/drive/MyDrive/ColabNotebooks/AnomalyDetection/graphs')
save_dir.mkdir(parents=True, exist_ok=True)
save_path = save_dir / 'nf_bot_iot_v2.2_graphs.pt'

torch.save({
    'graphs': graph_sequence,
    'features': numerical_features,
    'window_size': WINDOW_SIZE,
    'node_feature_dim': new_feat_dim
}, save_path)

print(f"Saved graph sequence to {save_path}")

if graph_sequence:
    num_nodes_per_graph = [g.num_nodes for g in graph_sequence]

    def get_num_edges(graph):
        if graph.edge_index.dim() == 2 and graph.edge_index.shape[1] > 0:
            return graph.edge_index.shape[1]
        else:
            return 0

    num_edges_per_graph = [get_num_edges(g) for g in graph_sequence]

    graph_labels = [g.y.item() for g in graph_sequence]

    print(f"Total graphs generated: {len(graph_sequence)}")

    print("Number of Nodes per Graph:")
    print(f"  Min: {min(num_nodes_per_graph)}")
    print(f"  Max: {max(num_nodes_per_graph)}")
    print(f"  Mean: {np.mean(num_nodes_per_graph):.2f}")
    print(f"  Median: {np.median(num_nodes_per_graph)}")

    print("Number of Edges per Graph (NOTE: Doubled due to undirected conversion):")
    print(f"  Min: {min(num_edges_per_graph)}")
    print(f"  Max: {max(num_edges_per_graph)}")
    print(f"  Mean: {np.mean(num_edges_per_graph):.2f}")
    print(f"  Median: {np.median(num_edges_per_graph)}")

    print("Distribution of Graph Labels (0=Benign, 1=Attack):")
    label_counts = pd.Series(graph_labels).value_counts().sort_index()
    print(label_counts)
    print(f"  Benign graphs: {label_counts.get(0, 0)} ({label_counts.get(0, 0)/len(graph_labels)*100:.2f}%)")
    print(f"  Attack graphs: {label_counts.get(1, 0)} ({label_counts.get(1, 0)/len(graph_labels)*100:.2f}%)")

else:
    print("No graphs in the sequence to save or visualize statistics for.")

def visualize_pyg_graph(graph, title, max_edges=500):
    if graph is None:
        print(f"{title} graph is None.")
        return

    def get_num_edges(g):
        if g.edge_index.dim() == 2 and g.edge_index.shape[1] > 0:
            return g.edge_index.shape[1]
        return 0

    total_edges = get_num_edges(graph)

    if total_edges == 0:
        print(f"{title} (Label: {graph.y.item()}) has 0 edges. Skipping visualization.")
        return

    edges = graph.edge_index.t().tolist()

    if total_edges > max_edges:
        print(f"Limiting edges from {total_edges} to {max_edges} for visualization.")
        edges = random.sample(edges, max_edges)

    G = nx.DiGraph()
    G.add_nodes_from(range(graph.num_nodes))

    G.add_edges_from([tuple(e) for e in edges])

    plt.figure(figsize=(10, 8))
    pos = nx.spring_layout(G, k=0.5, iterations=50, seed=42)
    nx.draw(G, pos,
            with_labels=True,
            node_color='skyblue',
            node_size=600,
            edge_color='gray',
            width=1.2,
            arrowsize=10,
            font_size=9)
    plt.title(f"{title} (Label: {graph.y.item()})")
    plt.axis('off')
    plt.show()

benign_graph = next((g for g in graph_sequence if g.y.item() == 0), None)
attack_graph = next((g for g in graph_sequence if g.y.item() == 1), None)

visualize_pyg_graph(benign_graph, "Benign Graph", max_edges=500)

visualize_pyg_graph(attack_graph, "Attack Graph", max_edges=500)